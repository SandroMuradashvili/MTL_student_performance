{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SandroMuradashvili/MTL_student_performance/blob/main/MTL_student_performance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1124,
      "metadata": {
        "id": "HBe4tzJBbWNE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from sklearn.metrics import mean_absolute_error, accuracy_score, f1_score\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8wGC4vDBbWUb",
        "outputId": "56c7e895-2bb0-415f-8798-fc0c62b79298"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'G3']\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# 1. Load the data | STEP 1\n",
        "# -----------------------------\n",
        "url = \"https://raw.githubusercontent.com/SandroMuradashvili/MTL_student_performance/refs/heads/main/data/student-por.csv\"\n",
        "\n",
        "# Read CSV with correct separator\n",
        "#df = pd.read_csv(url, sep=';')\n",
        "df = pd.read_csv(url, sep=';', header=0)  # explicitly use first row as header\n",
        "\n",
        "\n",
        "# Strip any leading/trailing whitespace from column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "\n",
        "# Check columns\n",
        "print(df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "E5p-eOgDbzlM",
        "outputId": "dbd04c81-5b84-4a13-825f-3ce0cf1c4f8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of raw dataset:\n",
            "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
            "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
            "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
            "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
            "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
            "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
            "\n",
            "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
            "0      4        3      4     1     1      3        4   0  11  11  \n",
            "1      5        3      3     1     1      3        2   9  11  11  \n",
            "2      4        3      2     2     3      3        6  12  13  12  \n",
            "3      3        2      2     1     1      5        0  14  14  14  \n",
            "4      4        3      2     1     2      5        0  11  13  13  \n",
            "\n",
            "[5 rows x 33 columns]\n",
            "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'G3']\n"
          ]
        }
      ],
      "source": [
        "#TEST\n",
        "# Show first 5 rows to understand the data\n",
        "print(\"First 5 rows of raw dataset:\")\n",
        "print(df.head())\n",
        "# Check columns\n",
        "print(df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1127,
      "metadata": {
        "id": "I1QbKt6PbWad"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# 2. Separate features and targets\n",
        "# -----------------------------\n",
        "# X = all columns except targets\n",
        "# y_grade = final grade (G3)\n",
        "# y_romantic = binary (0/1) for romantic relationship\n",
        "X = df.drop(columns=['G3', 'romantic'])\n",
        "y_grade = df['G3']\n",
        "y_romantic = df['romantic'].map({'yes': 1, 'no': 0})  # convert to 0/1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1128,
      "metadata": {
        "id": "pzJINdIzbWfN"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# 3. Split data into train, val, test\n",
        "# -----------------------------\n",
        "# First split: train+val vs test (12% test)\n",
        "X_temp, X_test, y_grade_temp, y_grade_test, y_romantic_temp, y_romantic_test = train_test_split(\n",
        "    X, y_grade, y_romantic, test_size=0.12, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "# Second split: train vs val (15% of train+val becomes validation)\n",
        "X_train, X_val, y_grade_train, y_grade_val, y_romantic_train, y_romantic_val = train_test_split(\n",
        "    X_temp, y_grade_temp, y_romantic_temp, test_size=0.15, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "#ADJUST 1 | 0.12 & 0.15\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DYJb4aVjb4za",
        "outputId": "cccb3a78-c687-47ae-b1f2-d6e6bdcc2e96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset sizes after splitting:\n",
            "Train: 485 samples (~75%)\n",
            "Validation: 86 samples (~13%)\n",
            "Test: 78 samples (~12%)\n"
          ]
        }
      ],
      "source": [
        "#Test\n",
        "# Print dataset sizes\n",
        "print(\"\\nDataset sizes after splitting:\")\n",
        "print(f\"Train: {X_train.shape[0]} samples (~75%)\")\n",
        "print(f\"Validation: {X_val.shape[0]} samples (~13%)\")\n",
        "print(f\"Test: {X_test.shape[0]} samples (~12%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1130,
      "metadata": {
        "id": "nrdxXjf1bWkn"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# 4. Identify categorical and numerical columns\n",
        "# -----------------------------\n",
        "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RtmrM3COcAEf",
        "outputId": "1255d556-c426-407c-ce7c-e04a283fba7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Categorical columns: ['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet']\n",
            "Numerical columns: ['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2']\n"
          ]
        }
      ],
      "source": [
        "#Test\n",
        "print(\"\\nCategorical columns:\", categorical_cols)\n",
        "print(\"Numerical columns:\", numerical_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1132,
      "metadata": {
        "id": "NsrfF4YabrQJ"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# 5. Preprocessing: One-hot encode categorical, standardize numerical\n",
        "# -----------------------------\n",
        "categorical_transformer = OneHotEncoder(drop='first', sparse_output=False)  # avoid dummy variable trap\n",
        "numerical_transformer = StandardScaler()\n",
        "\n",
        "# Combine preprocessing steps\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Fit the preprocessor only on training data to avoid data leakage\n",
        "preprocessor.fit(X_train)\n",
        "\n",
        "# Transform train, val, test sets\n",
        "X_train_proc = preprocessor.transform(X_train)\n",
        "X_val_proc = preprocessor.transform(X_val)\n",
        "X_test_proc = preprocessor.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "erigpv8XcDJ8",
        "outputId": "cf8bbf02-f711-4392-876e-d7c8083bd524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_proc: [[ 0.16583729  1.34192829  1.58561977 ...  0.          1.\n",
            "   1.        ]\n",
            " [ 0.97827249 -1.32179021 -1.17074434 ...  1.          0.\n",
            "   1.        ]\n",
            " [-0.64659791  1.34192829  1.58561977 ...  1.          0.\n",
            "   1.        ]\n",
            " ...\n",
            " [-0.64659791 -0.43388404 -0.25195631 ...  1.          1.\n",
            "   1.        ]\n",
            " [ 0.16583729  0.45402212 -0.25195631 ...  1.          1.\n",
            "   0.        ]\n",
            " [ 0.97827249  0.45402212  0.66683173 ...  1.          1.\n",
            "   1.        ]]\n"
          ]
        }
      ],
      "source": [
        "#Test\n",
        "# Debug prints: check shapes after preprocessing\n",
        "# print(\"\\nPreprocessing done. Shapes of processed datasets:\")\n",
        "# print(\"X_train_proc:\", X_train_proc.shape)\n",
        "# print(\"X_val_proc:\", X_val_proc.shape)\n",
        "# print(\"X_test_proc:\", X_test_proc.shape)\n",
        "\n",
        "print(\"X_train_proc:\", X_train_proc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eISrmq-sbw3q",
        "outputId": "422309c8-4131-4c0a-9198-db45c97c6bd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PyTorch DataLoaders ready!\n",
            "Example batch from train_loader:\n",
            "X batch shape: torch.Size([32, 40])\n",
            "y_grade batch shape: torch.Size([32, 1])\n",
            "y_romantic batch shape: torch.Size([32])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# -----------------------------\n",
        "# 6. Create PyTorch Dataset class\n",
        "# -----------------------------\n",
        "class StudentDataset(Dataset):\n",
        "    def __init__(self, X, y_grade, y_romantic):\n",
        "        # Convert numpy arrays / pandas Series to PyTorch tensors\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y_grade = torch.tensor(y_grade.values, dtype=torch.float32).unsqueeze(1)  # regression target\n",
        "        self.y_romantic = torch.tensor(y_romantic.values, dtype=torch.long)  # classification target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y_grade[idx], self.y_romantic[idx]\n",
        "\n",
        "# -----------------------------\n",
        "# 7. Create datasets and loaders\n",
        "# -----------------------------\n",
        "train_dataset = StudentDataset(X_train_proc, y_grade_train, y_romantic_train)\n",
        "val_dataset = StudentDataset(X_val_proc, y_grade_val, y_romantic_val)\n",
        "test_dataset = StudentDataset(X_test_proc, y_grade_test, y_romantic_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "#ADJUST 2 | batch size=32\n",
        "# Batch smaller | Often needs smaller LR |\n",
        "# Batch larger | Can use bigger LR |\n",
        "\n",
        "print(\"\\nPyTorch DataLoaders ready!\")\n",
        "print(\"Example batch from train_loader:\")\n",
        "example_batch = next(iter(train_loader))\n",
        "print(\"X batch shape:\", example_batch[0].shape)\n",
        "print(\"y_grade batch shape:\", example_batch[1].shape)\n",
        "print(\"y_romantic batch shape:\", example_batch[2].shape)\n",
        "\n",
        "print()\n",
        "\n",
        "#STEP 1 FINISHED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9sFTEYOL8c6I",
        "outputId": "36492df8-fdd2-47be-94cd-d7ef7ba6c4ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
            "       'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2',\n",
            "       'G3', 'school_GP', 'school_MS', 'sex_F', 'sex_M', 'address_R',\n",
            "       'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T',\n",
            "       'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services',\n",
            "       'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other',\n",
            "       'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home',\n",
            "       'reason_other', 'reason_reputation', 'guardian_father',\n",
            "       'guardian_mother', 'guardian_other', 'schoolsup_no', 'schoolsup_yes',\n",
            "       'famsup_no', 'famsup_yes', 'paid_no', 'paid_yes', 'activities_no',\n",
            "       'activities_yes', 'nursery_no', 'nursery_yes', 'higher_no',\n",
            "       'higher_yes', 'internet_no', 'internet_yes', 'romantic_no',\n",
            "       'romantic_yes'],\n",
            "      dtype='object')\n",
            "Total features: 59\n"
          ]
        }
      ],
      "source": [
        "encoded = pd.get_dummies(df, drop_first=False)\n",
        "print(encoded.columns)\n",
        "print(\"Total features:\", len(encoded.columns))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MhpdzxiF_Zj1",
        "outputId": "dd6b50fb-dd8d-480b-93ed-cba15058ce41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All columns in encoded DataFrame:\n",
            "['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'G3', 'school_GP', 'school_MS', 'sex_F', 'sex_M', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'schoolsup_no', 'schoolsup_yes', 'famsup_no', 'famsup_yes', 'paid_no', 'paid_yes', 'activities_no', 'activities_yes', 'nursery_no', 'nursery_yes', 'higher_no', 'higher_yes', 'internet_no', 'internet_yes', 'romantic_no', 'romantic_yes']\n",
            "\n",
            "Columns used in X (inputs to the model):\n",
            "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2']\n",
            "\n",
            "Number of input features: 40\n",
            "Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
            "       'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2',\n",
            "       'G3', 'school_GP', 'school_MS', 'sex_F', 'sex_M', 'address_R',\n",
            "       'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T',\n",
            "       'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services',\n",
            "       'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other',\n",
            "       'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home',\n",
            "       'reason_other', 'reason_reputation', 'guardian_father',\n",
            "       'guardian_mother', 'guardian_other', 'schoolsup_no', 'schoolsup_yes',\n",
            "       'famsup_no', 'famsup_yes', 'paid_no', 'paid_yes', 'activities_no',\n",
            "       'activities_yes', 'nursery_no', 'nursery_yes', 'higher_no',\n",
            "       'higher_yes', 'internet_no', 'internet_yes', 'romantic_no',\n",
            "       'romantic_yes'],\n",
            "      dtype='object')\n",
            "Total features: 59\n"
          ]
        }
      ],
      "source": [
        "# 1) All columns after one-hot encoding (or just the DataFrame you used for preprocessing)\n",
        "print(\"All columns in encoded DataFrame:\")\n",
        "print(encoded.columns.tolist())\n",
        "\n",
        "# 2) Columns used for training (X)\n",
        "print(\"\\nColumns used in X (inputs to the model):\")\n",
        "print(X.columns.tolist())\n",
        "\n",
        "# 3) Number of features in input to the model\n",
        "print(\"\\nNumber of input features:\", X_train_proc.shape[1])\n",
        "\n",
        "encoded = pd.get_dummies(df, drop_first=False)\n",
        "print(encoded.columns)\n",
        "print(\"Total features:\", len(encoded.columns))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1137,
      "metadata": {
        "id": "uJg6hPmjbWq-"
      },
      "outputs": [],
      "source": [
        "class MultiTaskModel(nn.Module):\n",
        "    def __init__(self, input_dim=40, shared_dim1=128, shared_dim2=64, head_dim=32, dropout=0.3):\n",
        "        super(MultiTaskModel, self).__init__()\n",
        "\n",
        "        # -------------------------\n",
        "        # 1) Shared Body (feature extractor) | STEP 2\n",
        "        # -------------------------\n",
        "        self.shared_body = nn.Sequential(\n",
        "            nn.Linear(input_dim, shared_dim1),   # 40 -> 128\n",
        "            nn.BatchNorm1d(shared_dim1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.Linear(shared_dim1, shared_dim2), # 128 -> 64\n",
        "            nn.BatchNorm1d(shared_dim2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # -------------------------\n",
        "        # 2) Head 1 → Grade Regression (predict G3)\n",
        "        # -------------------------\n",
        "        self.head_grade = nn.Sequential(\n",
        "            nn.Linear(shared_dim2, head_dim),    # 64 -> 32\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(head_dim, 1)               # Output single number\n",
        "        )\n",
        "\n",
        "        # -------------------------\n",
        "        # 3) Head 2 → Romantic Classification (0/1)\n",
        "        # -------------------------\n",
        "        self.head_romantic = nn.Sequential(\n",
        "            nn.Linear(shared_dim2, head_dim),    # 64 -> 32\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(head_dim, 2)               # 2 output logits\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        shared = self.shared_body(x)         # common features\n",
        "        grade_pred = self.head_grade(shared) # regression output\n",
        "        romantic_logits = self.head_romantic(shared) # classification logits\n",
        "        return grade_pred, romantic_logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1138,
      "metadata": {
        "id": "lRyPjryjej82"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define Model\n",
        "\n",
        "model = MultiTaskModel(input_dim=40)\n",
        "\n",
        "# -------------------------------\n",
        "# 1) Loss functions | STEP 3\n",
        "# -------------------------------\n",
        "loss_regression = nn.MSELoss()         # for grade prediction (G3)\n",
        "loss_classification = nn.CrossEntropyLoss()  # for romantic yes/no\n",
        "\n",
        "# -------------------------------\n",
        "# 2) Optimizer\n",
        "# -------------------------------\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# -------------------------------\n",
        "# 3) Training Loop\n",
        "# -------------------------------\n",
        "def train_model(model, train_loader, val_loader, alpha=0.5, epochs=30, device=\"cpu\"):\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        total_grade_loss = 0\n",
        "        total_rom_loss = 0\n",
        "\n",
        "        for X, y_grade, y_romantic in train_loader:\n",
        "\n",
        "            X, y_grade = X.to(device), y_grade.to(device).float()\n",
        "            y_romantic = y_romantic.to(device).long()\n",
        "\n",
        "            # Forward pass → two outputs\n",
        "            pred_grade, romantic_logits = model(X)\n",
        "\n",
        "            # --- Compute losses separately ---\n",
        "            grade_loss = loss_regression(pred_grade, y_grade)\n",
        "            romantic_loss = loss_classification(romantic_logits, y_romantic)\n",
        "\n",
        "            # --- Combine losses ---\n",
        "            #total_loss = grade_loss + romantic_loss # original.\n",
        "\n",
        "            # -----------------------------\n",
        "            # Weighted loss # BONUS\n",
        "            # -----------------------------\n",
        "            # alpha = 0.005   # <--- importance of G3 in % | UPDATE, instead of manual alpha is passed as parameter\n",
        "            total_loss = alpha * grade_loss + (1 - alpha) * romantic_loss\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # accumulate stats for reporting later\n",
        "            total_train_loss += total_loss.item()\n",
        "            total_grade_loss += grade_loss.item()\n",
        "            total_rom_loss   += romantic_loss.item()\n",
        "\n",
        "\n",
        "        # -----------------------------\n",
        "        # Validation (no backprop)\n",
        "        # -----------------------------\n",
        "        model.eval()\n",
        "        val_grade_loss = 0\n",
        "        val_rom_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X, y_grade, y_romantic in val_loader:\n",
        "                X, y_grade = X.to(device), y_grade.to(device).float()\n",
        "                y_romantic = y_romantic.to(device).long()\n",
        "\n",
        "                pred_g, logit_r = model(X)\n",
        "\n",
        "                val_grade_loss += loss_regression(pred_g, y_grade).item()\n",
        "                val_rom_loss   += loss_classification(logit_r, y_romantic).item()\n",
        "\n",
        "        # Print each epoch for debugging purposes\n",
        "        # print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "        #       f\"Train total: {total_train_loss:.4f} | \"\n",
        "        #       f\"Grade: {total_grade_loss:.4f} | \"\n",
        "        #       f\"Romantic: {total_rom_loss:.4f} || \"\n",
        "        #       f\"Val Grade: {val_grade_loss:.4f} | Val Romantic: {val_rom_loss:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1139,
      "metadata": {
        "id": "ipaWFOFzT0ab"
      },
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "#  STEP 4\n",
        "# -------------------------------\n",
        "\n",
        "def evaluate_on_test(model, test_loader, device=\"cpu\"):\n",
        "    model.eval()\n",
        "\n",
        "    true_grade = []\n",
        "    pred_grade = []\n",
        "\n",
        "    true_rom = []\n",
        "    pred_rom = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y_grade, y_romantic in test_loader:\n",
        "            X = X.to(device)\n",
        "\n",
        "            # forward pass\n",
        "            grade_out, romantic_logits = model(X)\n",
        "\n",
        "            # ---- Regression ----\n",
        "            true_grade.extend(y_grade.numpy())\n",
        "            pred_grade.extend(grade_out.cpu().numpy())\n",
        "\n",
        "            # ---- Classification ----\n",
        "            predicted = torch.argmax(romantic_logits, dim=1).cpu()\n",
        "\n",
        "            true_rom.extend(y_romantic.numpy())\n",
        "            pred_rom.extend(predicted.numpy())\n",
        "\n",
        "    # ---- Compute Metrics ----\n",
        "    mae = mean_absolute_error(true_grade, pred_grade)\n",
        "    accuracy = accuracy_score(true_rom, pred_rom)\n",
        "    f1 = f1_score(true_rom, pred_rom, pos_label=1)   # only for \"yes\" class\n",
        "\n",
        "    print(\"\\n========== FINAL TEST RESULTS ==========\")\n",
        "    print(f\"Mean Absolute Error (G3 Regression): {mae:.4f}\")\n",
        "    print(f\"Accuracy (Romantic Status)        : {accuracy:.4f}\")\n",
        "    print(f\"F1-Score (Romantic = YES)         : {f1:.4f}\")\n",
        "    print(\"=========================================\")\n",
        "\n",
        "    return mae, accuracy, f1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QNlXGaaZvyyK",
        "outputId": "2faf368a-ba72-4d2c-b168-17ca303d9c80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== FINAL TEST RESULTS ==========\n",
            "Mean Absolute Error (G3 Regression): 1.7775\n",
            "Accuracy (Romantic Status)        : 0.5256\n",
            "F1-Score (Romantic = YES)         : 0.2745\n",
            "=========================================\n"
          ]
        }
      ],
      "source": [
        "train_model(model, train_loader, val_loader,alpha=0.01, epochs=30)\n",
        "\n",
        "evaluate_on_test(model, test_loader)\n",
        "\n",
        "torch.save(model.state_dict(), \"best_model.pth\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZSBGTfrfvF6",
        "outputId": "ac86d84e-4c2a-4d5b-eddc-2ddfebdb5255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== FINAL TEST RESULTS ==========\n",
            "Mean Absolute Error (G3 Regression): 1.9529\n",
            "Accuracy (Romantic Status)        : 0.6282\n",
            "F1-Score (Romantic = YES)         : 0.1212\n",
            "=========================================\n"
          ]
        }
      ],
      "source": [
        "model_2 = MultiTaskModel(input_dim=40)\n",
        "\n",
        "optimizer = Adam(model_2.parameters(), lr=0.001)\n",
        "\n",
        "train_model(model_2, train_loader, val_loader,alpha=0.5, epochs=30)\n",
        "\n",
        "evaluate_on_test(model_2, test_loader)\n",
        "\n",
        "torch.save(model_2.state_dict(), \"best_model_2.pth\")\n",
        "\n",
        "# ALPHA\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = MultiTaskModel(input_dim=40)\n",
        "\n",
        "optimizer = Adam(model_3.parameters(), lr=0.001)\n",
        "\n",
        "train_model(model_3, train_loader, val_loader,alpha=0.8, epochs=30)\n",
        "\n",
        "evaluate_on_test(model_3, test_loader)\n",
        "\n",
        "torch.save(model_3.state_dict(), \"best_model_3.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFssSHET9eKw",
        "outputId": "c47990c9-1e68-40d9-e019-d3007ee21a39"
      },
      "execution_count": 1150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== FINAL TEST RESULTS ==========\n",
            "Mean Absolute Error (G3 Regression): 2.0933\n",
            "Accuracy (Romantic Status)        : 0.6026\n",
            "F1-Score (Romantic = YES)         : 0.1143\n",
            "=========================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5YIqOgauvR25kMYNIE1DB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}